#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
ç¬¬å››é˜¶æ®µé›¶çŸ¥è¯†è¯æ˜ç”Ÿæˆæ¨¡å—

åŠŸèƒ½ï¼š
1. ä¸ºæ°´å°æ•°æ®é›†ç”Ÿæˆé›¶çŸ¥è¯†è¯æ˜
2. å­¦ä¹  LSB_groth16/create_LSB_i.py çš„é€»è¾‘
3. åˆ›å»ºä¹°å®¶å“ˆå¸Œå¯¹åº”çš„å®éªŒç›®å½•
4. å¤åˆ¶åˆ†å—æ•°æ®å’Œé…ç½®æ–‡ä»¶
5. æ‰§è¡Œå®Œæ•´çš„è¯æ˜ç”Ÿæˆæµç¨‹
"""

import os
import shutil
import subprocess
import time
import logging
from typing import Dict, Any, List
from pathlib import Path

# å¯¼å…¥è¯æ˜æ‰“åŒ…ç”Ÿæˆå™¨
try:
    # å°è¯•ç›¸å¯¹å¯¼å…¥
    from .proof_package_generator import auto_package_proof_on_completion
except ImportError:
    # å¦‚æœç›¸å¯¹å¯¼å…¥å¤±è´¥ï¼Œä½¿ç”¨ç»å¯¹å¯¼å…¥
    from proof_package_generator import auto_package_proof_on_completion


class Stage4ProofGenerator:
    """ç¬¬å››é˜¶æ®µé›¶çŸ¥è¯†è¯æ˜ç”Ÿæˆå™¨"""

    def __init__(self, lsb_groth16_base: str = None):
        """
        åˆå§‹åŒ–ç¬¬å››é˜¶æ®µè¯æ˜ç”Ÿæˆå™¨
        
        Args:
            lsb_groth16_base: LSB_groth16 åŸºç¡€ç›®å½•è·¯å¾„
        """
        if lsb_groth16_base is None:
            # è‡ªåŠ¨æ£€æµ‹LSB_groth16ç›®å½•
            current_dir = os.path.dirname(os.path.abspath(__file__))
            project_root = os.path.dirname(os.path.dirname(current_dir))
            self.lsb_groth16_base = os.path.join(project_root, "LSB_groth16")
        else:
            self.lsb_groth16_base = lsb_groth16_base
        
        self.template_dir = os.path.join(self.lsb_groth16_base, "LSB_i")
        self.experiments_base = os.path.join(self.lsb_groth16_base, "LSB_experiments")
        
        logging.info(f"LSB_groth16è·¯å¾„: {self.lsb_groth16_base}")
        logging.info(f"æ¨¡æ¿è·¯å¾„: {self.template_dir}")
        logging.info(f"å®éªŒè·¯å¾„: {self.experiments_base}")
        
        # éªŒè¯å¿…è¦è·¯å¾„å­˜åœ¨
        if not os.path.exists(self.template_dir):
            raise FileNotFoundError(f"LSB_iæ¨¡æ¿ç›®å½•ä¸å­˜åœ¨: {self.template_dir}")
        if not os.path.exists(self.experiments_base):
            os.makedirs(self.experiments_base, exist_ok=True)

    def generate_proof_for_watermark(self, buy_hash: str, chunked_data_dir: str, 
                                   chunk_pixel_size: int, constraint_power: int,
                                   user_address: str = None) -> Dict[str, Any]:
        """
        ä¸ºç‰¹å®šä¹°å®¶å“ˆå¸Œçš„æ°´å°æ•°æ®ç”Ÿæˆé›¶çŸ¥è¯†è¯æ˜

        Args:
            buy_hash: ä¹°å®¶å“ˆå¸Œå€¼ï¼ˆå®Œæ•´å“ˆå¸Œï¼‰
            chunked_data_dir: åˆ†å—æ•°æ®ç›®å½•
            chunk_pixel_size: åˆ†å—åƒç´ å¤§å°ï¼ˆå¦‚29ï¼‰
            constraint_power: çº¦æŸåŠŸç‡ï¼ˆå¦‚16å¯¹åº”2^16ï¼‰
            user_address: ç”¨æˆ·åœ°å€ï¼ˆç”¨äºè¯æ˜åŒ…å‘½åï¼‰

        Returns:
            è¯æ˜ç”Ÿæˆç»“æœå­—å…¸
        """
        try:
            start_time = time.time()
            
            # 1. åˆ›å»ºå®éªŒç›®å½•
            experiment_name = buy_hash[:16]  # ä½¿ç”¨ä¹°å®¶å“ˆå¸Œå‰16å­—ç¬¦
            experiment_dir = os.path.join(self.experiments_base, experiment_name)
            
            logging.info(f"å¼€å§‹ä¸ºä¹°å®¶å“ˆå¸Œ {experiment_name} ç”Ÿæˆé›¶çŸ¥è¯†è¯æ˜...")
            if user_address:
                logging.info(f"ç”¨æˆ·åœ°å€: {user_address}")
            
            self._create_experiment_directory(experiment_dir)
            
            # 2. å¤åˆ¶åˆ†å—æ•°æ®
            self._copy_chunked_data(chunked_data_dir, experiment_dir, chunk_pixel_size)
            
            # 3. è®¾ç½®ptauæ–‡ä»¶
            self._setup_ptau_file(experiment_dir, constraint_power)
            
            # 4. æ›´æ–°é…ç½®æ–‡ä»¶
            self._update_configuration_files(experiment_dir, chunk_pixel_size, constraint_power)
            
            # 5. ç¼–è¯‘ç”µè·¯
            self._compile_circuit(experiment_dir)
            
            # 6. æ‰§è¡Œè¯æ˜ç”Ÿæˆæµç¨‹
            proof_results = self._execute_proof_pipeline(experiment_dir)
            
            # 7. éªŒè¯è¯æ˜
            verification_results = self._verify_proofs(experiment_dir)
            
            total_time = time.time() - start_time
            
            logging.info(f"âœ… é›¶çŸ¥è¯†è¯æ˜ç”Ÿæˆå®Œæˆï¼Œæ€»è€—æ—¶: {total_time:.2f}ç§’")
            logging.info(f"ğŸ‰ Stage 4é›¶çŸ¥è¯†è¯æ˜ç”ŸæˆæˆåŠŸå®Œæˆï¼")
            
            # 8. è‡ªåŠ¨ç”Ÿæˆè¯æ˜åŒ…ï¼ˆå¦‚æœæä¾›äº†ç”¨æˆ·åœ°å€ï¼‰
            package_result = None
            if user_address:
                logging.info(f"å¼€å§‹ä¸ºç”¨æˆ· {user_address} è‡ªåŠ¨ç”Ÿæˆè¯æ˜åŒ…...")
                package_result = auto_package_proof_on_completion(
                    user_address=user_address,
                    experiment_dir=experiment_dir,
                    buy_hash=buy_hash
                )
                
                if package_result and package_result.get("status") == "success":
                    logging.info(f"ğŸ è¯æ˜åŒ…è‡ªåŠ¨ç”ŸæˆæˆåŠŸ: {package_result['package_name']}")
                else:
                    logging.warning(f"âš ï¸ è¯æ˜åŒ…è‡ªåŠ¨ç”Ÿæˆå¤±è´¥ï¼Œä½†è¯æ˜ç”ŸæˆæˆåŠŸ")
            else:
                logging.info("æœªæä¾›ç”¨æˆ·åœ°å€ï¼Œè·³è¿‡è‡ªåŠ¨è¯æ˜åŒ…ç”Ÿæˆ")
            
            return {
                "status": "success",
                "experiment_dir": experiment_dir,
                "experiment_name": experiment_name,
                "buy_hash": buy_hash,
                "chunk_pixel_size": chunk_pixel_size,
                "constraint_power": constraint_power,
                "total_time": total_time,
                "proof_results": proof_results,
                "verification_results": verification_results,
                "user_address": user_address,
                "package_result": package_result
            }
            
        except Exception as e:
            logging.error(f"âŒ é›¶çŸ¥è¯†è¯æ˜ç”Ÿæˆå¤±è´¥: {str(e)}")
            return {
                "status": "error",
                "error": str(e),
                "buy_hash": buy_hash,
                "user_address": user_address
            }

    def _create_experiment_directory(self, experiment_dir: str):
        """åˆ›å»ºå®éªŒç›®å½•å¹¶å¤åˆ¶æ¨¡æ¿ï¼ˆå¦‚æœä¸å­˜åœ¨çš„è¯ï¼‰"""
        if os.path.exists(experiment_dir):
            logging.info(f"å®éªŒç›®å½•å·²å­˜åœ¨ï¼Œå°†ç›´æ¥ä½¿ç”¨: {experiment_dir}")
            return
        
        # å¤åˆ¶æ•´ä¸ªLSB_iæ¨¡æ¿ç›®å½•
        shutil.copytree(self.template_dir, experiment_dir)
        
        logging.info(f"âœ… æ¨¡æ¿å¤åˆ¶å®Œæˆ: {self.template_dir} â†’ {experiment_dir}")

    def _copy_chunked_data(self, chunked_data_dir: str, experiment_dir: str, chunk_pixel_size: int):
        """å¤åˆ¶åˆ†å—æ•°æ®åˆ°å®éªŒç›®å½•"""
        target_input_dir = os.path.join(experiment_dir, "LSB", f"input_json_chunk_pixel_{chunk_pixel_size}")
        
        # æ£€æŸ¥ç›®æ ‡ç›®å½•æ˜¯å¦å·²ç»å­˜åœ¨ä¸”åŒ…å«æ­£ç¡®çš„å­ç›®å½•ç»“æ„
        if os.path.exists(target_input_dir):
            # æ£€æŸ¥æ˜¯å¦æœ‰input_1, input_2ç­‰å­ç›®å½•
            subdirs = [d for d in os.listdir(target_input_dir) 
                       if os.path.isdir(os.path.join(target_input_dir, d)) and d.startswith('input_')]
            
            if subdirs:
                # ç»Ÿè®¡å­ç›®å½•ä¸­çš„JSONæ–‡ä»¶
                total_files = 0
                for subdir in subdirs:
                    subdir_path = os.path.join(target_input_dir, subdir)
                    json_files = [f for f in os.listdir(subdir_path) if f.endswith('.json')]
                    total_files += len(json_files)
                
                if total_files > 0:
                    logging.info(f"åˆ†å—æ•°æ®ç›®å½•å·²å­˜åœ¨ï¼ŒåŒ…å« {len(subdirs)} ä¸ªå­ç›®å½•å’Œ {total_files} ä¸ªJSONæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶")
                    return
            else:
                # æ£€æŸ¥æ˜¯å¦æœ‰å¹³é“ºçš„JSONæ–‡ä»¶ï¼ˆæ—§æ ¼å¼ï¼‰
                existing_files = [f for f in os.listdir(target_input_dir) if f.endswith('.json')]
                if existing_files:
                    logging.info(f"åˆ†å—æ•°æ®ç›®å½•å·²å­˜åœ¨ï¼ˆå¹³é“ºæ ¼å¼ï¼‰ï¼ŒåŒ…å« {len(existing_files)} ä¸ªJSONæ–‡ä»¶ï¼Œè·³è¿‡å¤åˆ¶")
                    return
            
            # å¦‚æœç›®å½•å­˜åœ¨ä½†ç»“æ„ä¸æ­£ç¡®ï¼Œåˆ é™¤é‡å»º
            logging.info("åˆ†å—æ•°æ®ç›®å½•å·²å­˜åœ¨ä½†ç»“æ„ä¸æ­£ç¡®ï¼Œå°†é‡æ–°å¤åˆ¶")
            shutil.rmtree(target_input_dir)
        
        # æ£€æŸ¥æºç›®å½•æ˜¯å¦å­˜åœ¨
        if not os.path.exists(chunked_data_dir):
            raise FileNotFoundError(f"åˆ†å—æ•°æ®æºç›®å½•ä¸å­˜åœ¨: {chunked_data_dir}")
        
        # å¤åˆ¶æ•´ä¸ªåˆ†å—æ•°æ®ç›®å½•
        shutil.copytree(chunked_data_dir, target_input_dir)
        
        # ç»Ÿè®¡å¤åˆ¶çš„æ–‡ä»¶æ•°é‡
        total_files = 0
        for root, dirs, files in os.walk(target_input_dir):
            total_files += len([f for f in files if f.endswith('.json')])
        
        logging.info(f"âœ… åˆ†å—æ•°æ®å¤åˆ¶å®Œæˆ: {total_files} ä¸ªJSONæ–‡ä»¶")
        logging.info(f"   æºç›®å½•: {chunked_data_dir}")
        logging.info(f"   ç›®æ ‡ç›®å½•: {target_input_dir}")

    def _setup_ptau_file(self, experiment_dir: str, constraint_power: int):
        """è®¾ç½®ptauæ–‡ä»¶"""
        ptau_filename = f"pot{constraint_power}_final.ptau"
        source_ptau = os.path.join(self.lsb_groth16_base, ptau_filename)
        target_ptau_dir = os.path.join(experiment_dir, "LSB", "ptau")
        target_ptau = os.path.join(target_ptau_dir, ptau_filename)
        
        if not os.path.exists(source_ptau):
            raise FileNotFoundError(f"æ‰¾ä¸åˆ°ptauæ–‡ä»¶: {source_ptau}")
        
        os.makedirs(target_ptau_dir, exist_ok=True)
        shutil.copy2(source_ptau, target_ptau)
        
        logging.info(f"âœ… ptauæ–‡ä»¶å¤åˆ¶å®Œæˆ: {ptau_filename}")

    def _update_configuration_files(self, experiment_dir: str, chunk_pixel_size: int, constraint_power: int):
        """æ›´æ–°é…ç½®æ–‡ä»¶ï¼šB_witness.py, C_zkey_time.py, LSB.circom"""
        lsb_dir = os.path.join(experiment_dir, "LSB")
        
        self._update_b_witness(lsb_dir, chunk_pixel_size)
        self._update_c_zkey(lsb_dir, constraint_power)
        self._update_lsb_circom(lsb_dir, chunk_pixel_size)

    def _update_b_witness(self, lsb_dir: str, chunk_pixel_size: int):
        """æ›´æ–°B_witness.pyæ–‡ä»¶"""
        b_witness_file = os.path.join(lsb_dir, "B_witness.py")
        
        with open(b_witness_file, "r", encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢è¾“å…¥ç›®å½•å ä½ç¬¦
        content = content.replace(
            "input_json_chunk_pixel_hownumberPixels", 
            f"input_json_chunk_pixel_{chunk_pixel_size}"
        )
        
        # ä¿®å¤Windowsè·¯å¾„åˆ†éš”ç¬¦ä¸ºUnixæ ¼å¼ï¼ˆé’ˆå¯¹macOS/Linuxï¼‰
        content = content.replace("LSB_js\\generate_witness.js", "LSB_js/generate_witness.js")
        content = content.replace("LSB_js\\LSB.wasm", "LSB_js/LSB.wasm")
        
        with open(b_witness_file, "w", encoding='utf-8') as f:
            f.write(content)
        
        logging.info(f"âœ… B_witness.py å·²æ›´æ–°ï¼Œè¾“å…¥ç›®å½•: input_json_chunk_pixel_{chunk_pixel_size}ï¼Œè·¯å¾„åˆ†éš”ç¬¦å·²ä¿®å¤")

    def _update_c_zkey(self, lsb_dir: str, constraint_power: int):
        """æ›´æ–°C_zkey_time.pyæ–‡ä»¶"""
        c_zkey_file = os.path.join(lsb_dir, "C_zkey_time.py")
        
        with open(c_zkey_file, "r", encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢ptauæ–‡ä»¶å ä½ç¬¦
        ptau_filename = f"pot{constraint_power}_final.ptau"
        content = content.replace("pothownumberptau_final.ptau", ptau_filename)
        
        with open(c_zkey_file, "w", encoding='utf-8') as f:
            f.write(content)
        
        logging.info(f"âœ… C_zkey_time.py å·²æ›´æ–°ï¼Œptauæ–‡ä»¶: {ptau_filename}")

    def _update_lsb_circom(self, lsb_dir: str, chunk_pixel_size: int):
        """æ›´æ–°LSB.circomæ–‡ä»¶"""
        lsb_circom_file = os.path.join(lsb_dir, "LSB.circom")
        
        with open(lsb_circom_file, "r", encoding='utf-8') as f:
            content = f.read()
        
        # æ›¿æ¢åƒç´ æ•°é‡å ä½ç¬¦ï¼ˆéœ€è¦æ›¿æ¢æ‰€æœ‰å‡ºç°çš„ä½ç½®ï¼‰
        content = content.replace("hownumberPixels", str(chunk_pixel_size))
        content = content.replace("numPixelscheng3", str(chunk_pixel_size * 3))
        
        with open(lsb_circom_file, "w", encoding='utf-8') as f:
            f.write(content)
        
        logging.info(f"âœ… LSB.circom å·²æ›´æ–°ï¼Œåƒç´ æ•°: {chunk_pixel_size}ï¼Œæ€»ä¿¡å·æ•°: {chunk_pixel_size * 3}")

    def _compile_circuit(self, experiment_dir: str):
        """ç¼–è¯‘ç”µè·¯"""
        lsb_dir = os.path.join(experiment_dir, "LSB")
        
        logging.info("å¼€å§‹ç¼–è¯‘ç”µè·¯...")
        
        # åˆ›å»ºå¿…è¦çš„ç›®å½•
        os.makedirs(os.path.join(lsb_dir, "LSB_js"), exist_ok=True)
        
        # ç¼–è¯‘circomç”µè·¯
        compile_cmd = ["circom", "LSB.circom", "--r1cs", "--wasm", "-o", "."]
        
        result = subprocess.run(
            compile_cmd,
            cwd=lsb_dir,
            capture_output=True,
            text=True,
            timeout=300  # 5åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"ç”µè·¯ç¼–è¯‘å¤±è´¥: {result.stderr}")
        
        logging.info("âœ… ç”µè·¯ç¼–è¯‘å®Œæˆ")

    def _execute_proof_pipeline(self, experiment_dir: str) -> Dict[str, Any]:
        """æ‰§è¡Œè¯æ˜ç”Ÿæˆæµæ°´çº¿"""
        lsb_dir = os.path.join(experiment_dir, "LSB")
        results = {}
        
        # Bæ­¥éª¤ï¼šç”Ÿæˆwitnessæ–‡ä»¶
        logging.info("æ‰§è¡Œ B_witness.py...")
        start_time = time.time()
        
        result = subprocess.run(
            ["python", "B_witness.py"],
            cwd=lsb_dir,
            capture_output=True,
            text=True,
            timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"B_witness.py æ‰§è¡Œå¤±è´¥: {result.stderr}")
        
        results["B_witness"] = {
            "duration": time.time() - start_time,
            "status": "success"
        }
        logging.info(f"âœ… B_witness.py æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {results['B_witness']['duration']:.2f}ç§’")
        
        # Cæ­¥éª¤ï¼šç”Ÿæˆzkey
        logging.info("æ‰§è¡Œ C_zkey_time.py...")
        start_time = time.time()
        
        result = subprocess.run(
            ["python", "C_zkey_time.py"],
            cwd=lsb_dir,
            capture_output=True,
            text=True,
            timeout=3600  # 60åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"C_zkey_time.py æ‰§è¡Œå¤±è´¥: {result.stderr}")
        
        results["C_zkey"] = {
            "duration": time.time() - start_time,
            "status": "success"
        }
        logging.info(f"âœ… C_zkey_time.py æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {results['C_zkey']['duration']:.2f}ç§’")
        
        # Dæ­¥éª¤ï¼šç”Ÿæˆè¯æ˜
        logging.info("æ‰§è¡Œ D_proof_public.py...")
        start_time = time.time()
        
        result = subprocess.run(
            ["python", "D_proof_public.py"],
            cwd=lsb_dir,
            capture_output=True,
            text=True,
            timeout=3600  # 60åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"D_proof_public.py æ‰§è¡Œå¤±è´¥: {result.stderr}")
        
        results["D_proof"] = {
            "duration": time.time() - start_time,
            "status": "success"
        }
        logging.info(f"âœ… D_proof_public.py æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {results['D_proof']['duration']:.2f}ç§’")
        
        return results

    def _verify_proofs(self, experiment_dir: str) -> Dict[str, Any]:
        """éªŒè¯ç”Ÿæˆçš„è¯æ˜"""
        lsb_dir = os.path.join(experiment_dir, "LSB")
        
        logging.info("æ‰§è¡Œ E_verify_proof_public.py...")
        start_time = time.time()
        
        result = subprocess.run(
            ["python", "E_verify_proof_public.py"],
            cwd=lsb_dir,
            capture_output=True,
            text=True,
            timeout=1800  # 30åˆ†é’Ÿè¶…æ—¶
        )
        
        if result.returncode != 0:
            raise RuntimeError(f"E_verify_proof_public.py æ‰§è¡Œå¤±è´¥: {result.stderr}")
        
        verification_result = {
            "duration": time.time() - start_time,
            "status": "success"
        }
        
        logging.info(f"âœ… E_verify_proof_public.py æ‰§è¡Œå®Œæˆï¼Œè€—æ—¶: {verification_result['duration']:.2f}ç§’")
        
        # ç»Ÿè®¡ç”Ÿæˆçš„è¯æ˜æ–‡ä»¶
        proof_dir = os.path.join(lsb_dir, "proof_json")
        public_dir = os.path.join(lsb_dir, "public_json")
        
        proof_count = 0
        public_count = 0
        
        if os.path.exists(proof_dir):
            for root, dirs, files in os.walk(proof_dir):
                proof_count += len([f for f in files if f.endswith('.json')])
        
        if os.path.exists(public_dir):
            for root, dirs, files in os.walk(public_dir):
                public_count += len([f for f in files if f.endswith('.json')])
        
        verification_result.update({
            "proof_files_generated": proof_count,
            "public_files_generated": public_count
        })
        
        logging.info(f"è¯æ˜æ–‡ä»¶ç»Ÿè®¡: {proof_count} ä¸ªproofæ–‡ä»¶ï¼Œ{public_count} ä¸ªpublicæ–‡ä»¶")
        
        return verification_result


def test_stage4_proof_generation():
    """æµ‹è¯•ç¬¬å››é˜¶æ®µè¯æ˜ç”Ÿæˆ"""
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
    
    # æµ‹è¯•å‚æ•° - ä¿®æ”¹çº¦æŸåŠŸç‡ä¸º16
    test_buy_hash = "a158e72bdc06739d4b9f3139de796443209eefd90bf43deff2d5bd4902346e604022bcd825f28136e"
    test_chunked_data_dir = "/Users/dylan/Code_Projects/Python_Projects/image_similarity/my_agent_project/data/chunked_inputs/session_a158e72bdc06739d/chunk_pixel_29"
    test_chunk_pixel_size = 29
    test_constraint_power = 16  # æ”¹ä¸º16ï¼Œå› ä¸ºç”¨æˆ·åªæœ‰pot16_final.ptau
    
    generator = Stage4ProofGenerator()
    
    result = generator.generate_proof_for_watermark(
        buy_hash=test_buy_hash,
        chunked_data_dir=test_chunked_data_dir,
        chunk_pixel_size=test_chunk_pixel_size,
        constraint_power=test_constraint_power
    )
    
    print(f"æµ‹è¯•ç»“æœ: {result}")
    
    return result


if __name__ == "__main__":
    test_stage4_proof_generation()
