#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
å®Œæ•´çš„ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•è„šæœ¬
éªŒè¯æ£€æµ‹åˆ°æ°´å°åçš„å®Œæ•´æµç¨‹ï¼š
1. æ°´å°æ£€æµ‹
2. ç¬¬ä¸‰é˜¶æ®µæ•°æ®åˆ†å—å¤„ç†
3. Powers of Tauå‡†å¤‡
"""

import os
import sys
import json
import logging
import shutil

# æ·»åŠ featuresç›®å½•åˆ°path
sys.path.append(os.path.join(os.path.dirname(__file__), 'features'))

from feature_register import register_data

def test_complete_watermark_detection_and_chunking():
    """æµ‹è¯•å®Œæ•´çš„æ°´å°æ£€æµ‹å’Œåˆ†å—æµç¨‹"""
    print("=== å®Œæ•´çš„ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯• ===")
    
    # å‡†å¤‡æµ‹è¯•æ•°æ®
    dataset_dir = os.path.join(os.path.dirname(__file__), "data", "test_dataset_for_stage3")
    
    if not os.path.exists(dataset_dir):
        print("âŒ æµ‹è¯•æ•°æ®é›†ç›®å½•ä¸å­˜åœ¨")
        return False
    
    # æ£€æŸ¥æ•°æ®é›†å†…å®¹
    image_files = [f for f in os.listdir(dataset_dir) if f.endswith('.png')]
    print(f"ğŸ“‹ æµ‹è¯•æ•°æ®é›†: {len(image_files)} å¼ å›¾ç‰‡")
    for img in image_files:
        print(f"   - {img}")
    
    # åˆ›å»ºæµ‹è¯•ç”¨çš„metadata URLï¼ˆæ¨¡æ‹Ÿï¼‰
    # æ³¨æ„ï¼šè¿™ä¸ªæµ‹è¯•ä¼šä½¿ç”¨ç°æœ‰çš„æ•°æ®é›†ï¼Œè€Œä¸æ˜¯ä»ç½‘ç»œä¸‹è½½
    test_metadata_url = "http://test.example.com/metadata.json"
    test_user_address = "0x1234567890abcdef"
    
    print(f"\nğŸ” å¼€å§‹æµ‹è¯•æ°´å°æ£€æµ‹å’Œåˆ†å—æµç¨‹...")
    
    try:
        # å¤‡ä»½åŸå§‹register_dataå‡½æ•°çš„éƒ¨åˆ†é€»è¾‘ï¼Œæˆ‘ä»¬è¦ç›´æ¥æµ‹è¯•æ ¸å¿ƒéƒ¨åˆ†
        from features.checkForWatermark import main as check_watermark
        from features.poweroftau_generator import PowerOfTauGenerator
        
        # 1. æ•°æ®é›†åˆ†æ
        print("1. æ•°æ®é›†åˆ†æ...")
        generator = PowerOfTauGenerator()
        total_pixels = generator.calculate_dataset_pixels(dataset_dir)
        optimal_config = generator.get_optimal_constraints(total_pixels)
        
        print(f"   æ€»åƒç´ æ•°: {total_pixels}")
        print(f"   æœ€ä¼˜çº¦æŸ: 2^{optimal_config['power']} = {optimal_config['constraint_size']}")
        print(f"   åˆ†å—é…ç½®: M={optimal_config['M']}, m={optimal_config['m']}")
        
        # 2. æ°´å°æ£€æµ‹
        print("\n2. æ°´å°æ£€æµ‹...")
        
        # ç›´æ¥è°ƒç”¨æ°´å°æ£€æµ‹
        sys.argv = ['checkForWatermark.py', '--input', dataset_dir, '--verbose']
        
        # æ•è·æ°´å°æ£€æµ‹è¾“å‡º
        import subprocess
        wm_cmd = ["python", "features/checkForWatermark.py", "--input", dataset_dir, "--verbose"]
        wm_result = subprocess.run(wm_cmd, capture_output=True, text=True, check=True, timeout=120)
        wm_output = wm_result.stdout.strip()
        
        print(f"   æ£€æµ‹ç»“æœ: {wm_output.split()[0] if wm_output else 'None'}")
        
        # æ£€æŸ¥æ˜¯å¦æ£€æµ‹åˆ°æ°´å°
        result_line = wm_output.split('\n')[0] if '\n' in wm_output else wm_output
        
        if result_line != "1":
            print(f"âŒ æœªæ£€æµ‹åˆ°æ°´å°ï¼Œæ— æ³•æµ‹è¯•åˆ†å—æµç¨‹")
            return False
        
        print("   âœ… æ£€æµ‹åˆ°æ°´å°!")
        
        # 3. æå–ä¹°å®¶å“ˆå¸Œå€¼
        print("\n3. æå–ä¹°å®¶å“ˆå¸Œå€¼...")
        watermark_lines = wm_output.split('\n')
        detected_buy_hash = None
        
        for line in watermark_lines:
            if "æå–çš„å“ˆå¸Œå€¼:" in line or "åŒ¹é…çš„é¢„æœŸå“ˆå¸Œ:" in line:
                import re
                hash_match = re.search(r'[a-f0-9]{64}', line)
                if hash_match:
                    detected_buy_hash = hash_match.group(0)
                    break
        
        if not detected_buy_hash:
            print("âŒ æ— æ³•æå–ä¹°å®¶å“ˆå¸Œå€¼")
            return False
        
        print(f"   æ£€æµ‹åˆ°çš„ä¹°å®¶å“ˆå¸Œ: {detected_buy_hash[:16]}...")
        
        # 4. ç¬¬ä¸‰é˜¶æ®µæ•°æ®åˆ†å—å¤„ç†
        print("\n4. ç¬¬ä¸‰é˜¶æ®µæ•°æ®åˆ†å—å¤„ç†...")
        
        from stage3_chunk_and_proof import process_watermarked_dataset_registration
        
        chunking_result = process_watermarked_dataset_registration(
            buy_hash=detected_buy_hash,
            optimal_config=optimal_config
        )
        
        if chunking_result["status"] != "chunking_completed":
            print(f"âŒ åˆ†å—å¤„ç†å¤±è´¥: {chunking_result.get('message', 'Unknown error')}")
            return False
        
        print("   âœ… ç¬¬ä¸‰é˜¶æ®µåˆ†å—å¤„ç†å®Œæˆ!")
        chunk_info = chunking_result["chunking_result"]
        session_info = chunk_info["session_info"]
        
        print(f"   - å¤„ç†å›¾ç‰‡æ•°: {session_info['total_images']}")
        print(f"   - ç”Ÿæˆåˆ†å—æ•°: {session_info['total_chunks']}")
        print(f"   - åˆ†å—å¤§å°: {session_info['chunk_pixel_size']} åƒç´ /å—")
        print(f"   - è¾“å‡ºç›®å½•: {os.path.basename(session_info['output_directory'])}")
        
        # 5. éªŒè¯åˆ†å—æ–‡ä»¶
        print("\n5. éªŒè¯åˆ†å—æ–‡ä»¶...")
        chunk_output_dir = chunk_info["chunk_output_dir"]
        
        if not os.path.exists(chunk_output_dir):
            print(f"âŒ åˆ†å—è¾“å‡ºç›®å½•ä¸å­˜åœ¨: {chunk_output_dir}")
            return False
        
        # ç»Ÿè®¡åˆ†å—æ–‡ä»¶
        total_files = 0
        for root, dirs, files in os.walk(chunk_output_dir):
            json_files = [f for f in files if f.endswith('.json')]
            total_files += len(json_files)
        
        if total_files != session_info['total_chunks']:
            print(f"âŒ åˆ†å—æ–‡ä»¶æ•°é‡ä¸åŒ¹é…: æœŸæœ›{session_info['total_chunks']}, å®é™…{total_files}")
            return False
        
        print(f"   âœ… åˆ†å—æ–‡ä»¶éªŒè¯é€šè¿‡: {total_files} ä¸ªJSONæ–‡ä»¶")
        
        # éªŒè¯ç¬¬ä¸€ä¸ªåˆ†å—æ–‡ä»¶çš„æ ¼å¼
        first_chunk_file = None
        for root, dirs, files in os.walk(chunk_output_dir):
            json_files = [f for f in files if f.endswith('.json')]
            if json_files:
                first_chunk_file = os.path.join(root, json_files[0])
                break
        
        if first_chunk_file:
            try:
                with open(first_chunk_file, 'r') as f:
                    chunk_data = json.load(f)
                
                required_keys = ["originalPixelValues", "Watermark_PixelValues", 
                               "binaryWatermark", "binaryWatermark_num"]
                
                if all(key in chunk_data for key in required_keys):
                    pixel_count = len(chunk_data["originalPixelValues"])
                    watermark_num = chunk_data["binaryWatermark_num"]
                    print(f"   âœ… åˆ†å—æ ¼å¼æ­£ç¡®: {pixel_count} åƒç´ , watermark_num={watermark_num}")
                else:
                    print(f"   âŒ åˆ†å—æ ¼å¼é”™è¯¯: ç¼ºå°‘å¿…è¦å­—æ®µ")
                    return False
            except Exception as e:
                print(f"   âŒ åˆ†å—æ–‡ä»¶è¯»å–å¤±è´¥: {e}")
                return False
        
        # 6. æ¨¡æ‹ŸPowers of Tauå‡†å¤‡ï¼ˆä¸å®é™…æ‰§è¡Œï¼ŒåªéªŒè¯å‚æ•°ï¼‰
        print("\n6. Powers of Tauå‡†å¤‡éªŒè¯...")
        
        user_id = "TEST123"
        ptau_info = {
            "total_pixels": total_pixels,
            "optimal_config": optimal_config,
            "user_id": user_id,
            "dataset_folder": dataset_dir
        }
        
        constraint_power = optimal_config['power']
        print(f"   çº¦æŸå¹‚æ¬¡: 2^{constraint_power}")
        print(f"   ç”¨æˆ·ID: {user_id}")
        print(f"   âœ… Powers of Tauå‚æ•°å‡†å¤‡å®Œæˆ")
        
        print(f"\nğŸ‰ å®Œæ•´çš„ç¬¬ä¸‰é˜¶æ®µé›†æˆæµ‹è¯•é€šè¿‡!")
        print(f"âœ… æ°´å°æ£€æµ‹æ­£å¸¸")
        print(f"âœ… ä¹°å®¶å“ˆå¸Œæå–æ­£å¸¸") 
        print(f"âœ… ç¬¬ä¸‰é˜¶æ®µåˆ†å—å¤„ç†æ­£å¸¸")
        print(f"âœ… åˆ†å—æ–‡ä»¶æ ¼å¼æ­£ç¡®")
        print(f"âœ… Powers of Tauå‚æ•°å‡†å¤‡æ­£å¸¸")
        
        # è¾“å‡ºå…³é”®ä¿¡æ¯
        print(f"\nğŸ“Š å¤„ç†ç»“æœæ‘˜è¦:")
        print(f"   æ£€æµ‹åˆ°çš„ä¹°å®¶å“ˆå¸Œ: {detected_buy_hash}")
        print(f"   åˆ†å—é…ç½®: m={optimal_config['m']}, M={optimal_config['M']}")
        print(f"   çº¦æŸå¤§å°: 2^{optimal_config['power']} = {optimal_config['constraint_size']}")
        print(f"   åˆ†å—æ–‡ä»¶æ•°: {session_info['total_chunks']}")
        print(f"   åˆ†å—è¾“å‡ºç›®å½•: {chunk_output_dir}")
        
        return True
        
    except Exception as e:
        print(f"âŒ é›†æˆæµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    logging.basicConfig(level=logging.INFO, format="%(asctime)s - %(levelname)s - %(message)s")
    
    print("ğŸ§ª ç¬¬ä¸‰é˜¶æ®µå®Œæ•´é›†æˆæµ‹è¯•")
    print("=" * 60)
    
    success = test_complete_watermark_detection_and_chunking()
    
    print(f"\n" + "=" * 60)
    if success:
        print(f"ğŸ‰ ç¬¬ä¸‰é˜¶æ®µå®Œæ•´é›†æˆæµ‹è¯•æˆåŠŸ!")
        print(f"âœ… ä¿®å¤åçš„æµç¨‹æ­£å¸¸å·¥ä½œ")
        print(f"âœ… æ£€æµ‹åˆ°æ°´å°åä¼šæ­£ç¡®æ‰§è¡Œåˆ†å—å¤„ç†")
        print(f"âœ… ç”Ÿæˆçš„åˆ†å—æ–‡ä»¶ç¬¦åˆLSB_groth16æ ¼å¼")
    else:
        print(f"âŒ ç¬¬ä¸‰é˜¶æ®µå®Œæ•´é›†æˆæµ‹è¯•å¤±è´¥")
        print(f"éœ€è¦æ£€æŸ¥å’Œä¿®å¤ç›¸å…³é—®é¢˜")
    
    return success

if __name__ == "__main__":
    main() 
 
 