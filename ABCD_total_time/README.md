# 自适应分块算法 - ABCD 总时间优化

## 项目概述

本项目实现了一个完整的自适应分块算法，通过整合零知识证明系统中 ABCD 四个步骤的拟合公式，自动为给定分辨率的图像选择最优的约束配置，以最小化总执行时间。

### 算法原理

在零知识证明（Groth16 协议）中，证明生成过程包含四个主要步骤：

- **A 步骤**：创建 Power-of-Tau 公共参数
- **B 步骤**：生成见证文件（wtns）
- **C 步骤**：生成证明密钥（zkey）
- **D 步骤**：最终生成证明（proof.json）

总时间公式：

```
T_total(m) = T_A(X) + M × T_B(m,M) + T_C(m,M,X) + T_D(m,M,X)
```

其中：

- `N`：总像素数
- `m`：单块像素数
- `M = ⌈N/m⌉`：分块数量
- `X = 2^⌈log₂(m×2250)⌉`：约束大小（对齐到 2 的幂）

### 核心发现

1. **FFT 幂次台阶效应**：在同一 2^i 约束区间内，像素数越大，证明时间越短
2. **最优约束选择**：不同分辨率图像的最优约束可能不同
3. **时间构成分析**：各步骤对总时间的贡献比例

## 拟合公式

### A 步骤（分段函数）

```python
# 小规模（X ≤ 2^15）
T_A = 1.625375 + 2.574410e-03 × X

# 大规模（X > 2^15）
T_A = -113.042472 + 1.611649e-04 × X × log₂(X)
```

### B 步骤

```python
T_B = exp(-3.745 + 0.949×ln(pixel) - 0.002×ln(chunks))
```

### C 步骤

```python
T_C = 112.956 + 0.443×pixel - 6.382×ln(chunks) + 3.21e-05×X - 2.18e-05×pixel²
```

### D 步骤（两种模型）

**D_total_time 模型（推荐）：**

```python
T_D = -6.337 - 0.009×pixel + 0.548×chunks + 0.016×pixel×chunks
```

**D_time 模型：**

```python
T_D = (-15.193 - 0.026×pixel + 0.949×log₂(X) + 0.00173×pixel×log₂(X)) × chunks
```

## 使用方法

### 1. 完整分析（多个图像）

```bash
cd ABCD_total_time/code
python adaptive_block_algorithm.py
```

这将分析预设的多个图像分辨率（21420, 96480, 193000, 500000 像素），并生成：

- 详细的约束组合分析
- 性能评估结果
- 最优约束选择
- 可视化图表

### 2. 单个图像分析

#### 交互式模式

```bash
python single_image_analysis.py
```

按提示输入像素数和模型选择。

#### 命令行模式

```bash
# 分析21420像素图像，使用D_total_time模型
python single_image_analysis.py 21420

# 分析96480像素图像，使用D_time模型，简化输出
python single_image_analysis.py 96480 --d-model single --simple

# 分析自定义分辨率，不保存结果文件
python single_image_analysis.py 300000 --no-save
```

### 3. Python API 调用

```python
from adaptive_block_algorithm import AdaptiveBlockAlgorithm

# 创建算法实例
algorithm = AdaptiveBlockAlgorithm()

# 分析特定像素数
total_pixels = 100000
optimal, results, constraint_groups = algorithm.run_analysis(total_pixels)

print(f"最优约束: 2^{optimal['power']}")
print(f"最优配置: M={optimal['M']}, m={optimal['m']}")
print(f"总时间: {optimal['total_time']:.2f} 秒")
```

## 输出文件

运行后会在相应目录生成：

### results/

- `performance_evaluation.csv`：各约束下的性能评估结果
- `constraint_combinations.csv`：所有约束组合的详细信息
- `optimal_summary.csv`：最优结果摘要

### figures/

- `adaptive_block_analysis.png`：综合分析图表

## 示例输出

```
=== 分析图像分辨率: 21420 像素 ===
每像素约束数: 2250

=== 详细约束组合分析 ===

约束 2^16 = 65536:
  共有 14 个(M,m)组合
    分块数M   像素数m   实际总像素      约束数
        15      1428       21420      3213000
        16      1339       21424      3012750
        17      1260       21420      2835000
        18      1190       21420      2677500
        19      1128       21432      2538000

=== 性能评估（使用D_total_time模型） ===
      约束   分块数M   像素数m   A_time   B_time   C_time   D_time      总时间
--------------------------------------------------------------------------------
2^16       15     1428      84.5     38.9   -3029.0    320.4    -2585.2
2^17       18     1190     180.3     47.2   -2811.2    431.3    -2152.4
2^18       20     1071     372.0     53.8   -2695.0    510.6    -1758.6
...

=== 最优约束分析 ===
最优约束: 2^25 = 33554432
最优分块数M: 1
最优单块像素数m: 21420
最短总时间: 48180.82 秒

时间构成:
  A步骤: 47970.40 秒 (99.6%)
  B步骤: 21.68 秒 (0.0%)
  C步骤: 188.14 秒 (0.4%)
  D步骤: 0.60 秒 (0.0%)
```

## 关键特性

### 1. FFT 幂次台阶效应验证

算法自动验证并利用 FFT 幂次台阶效应：在同一约束区间内选择像素数最大的组合。

### 2. 多模型支持

支持两种 D 步骤模型：

- `D_total_time`：直接预测总时间（推荐，误差 7.66%）
- `D_time`：预测单次时间再乘以分块数（误差 22.27%）

### 3. 全面性能分析

- 各约束下的详细组合分析
- ABCD 步骤的时间构成分析
- 最优约束的自动选择
- 处理效率分析

### 4. 可视化输出

生成包含 6 个子图的综合分析图表：

- 总执行时间对比
- 各步骤时间分布
- 时间构成堆叠图
- 分块数变化
- 单块像素数变化
- 处理效率分析

## 适用范围

- **像素数范围**：20 - 500,000（可扩展）
- **约束范围**：2^16 - 2^25
- **分块数范围**：1 - 10,000
- **每像素约束数**：2250（可配置）

## 技术细节

### 依赖库

```python
numpy>=1.21.0
pandas>=1.3.0
matplotlib>=3.4.0
scipy>=1.7.0
```

### 核心算法复杂度

- 约束组合计算：O(N)，其中 N 为总像素数
- 性能评估：O(k)，其中 k 为不同约束数量（通常 ≤10）
- 总体复杂度：O(N)，线性时间复杂度

### 精度说明

- A 步骤：分段拟合，小规模误差<5%，大规模误差<3%
- B 步骤：R²=0.998，平均相对误差 2.35%
- C 步骤：R²=0.977，平均相对误差 9.65%
- D 步骤：R²=0.977（D_total），平均相对误差 7.66%

## 常见问题

### Q: 为什么有时候最优约束是 2^25？

A: 对于小规模图像，A 步骤时间随约束大小的增长较慢，而较大约束可以减少分块数，降低其他步骤的时间。但实际应用中需要考虑内存限制。

### Q: 两种 D 模型应该选择哪个？

A: 推荐使用`D_total_time`模型，因为：

1. 相对误差更小（7.66% vs 22.27%）
2. 直接预测总时间，更适合实际应用
3. 避免了小值相对误差放大的问题

### Q: 如何处理超大图像？

A: 算法支持任意大小图像，但需要注意：

1. 计算时间随像素数线性增长
2. 内存使用需要实际验证
3. 可能需要调整最大分块数限制

## 开发说明

### 添加新的拟合公式

在`AdaptiveBlockAlgorithm`类中修改相应的预测函数即可。

### 扩展约束范围

修改`calculate_constraint_groups`方法中的约束范围判断。

### 自定义权重策略

在各步骤的拟合公式中可以添加不同的权重考虑。

## 贡献

欢迎提交 Issues 和 Pull Requests 来改进算法性能和功能。

## 许可证

本项目采用 MIT 许可证。
